{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from widerface_evaluate.evaluation import get_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Predictions : 100%|██████████| 61/61 [00:00<00:00, 77.65it/s] \n"
     ]
    }
   ],
   "source": [
    "preds = get_preds('./widerface_evaluate/widerface_txt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['27--Spa',\n",
       " '1--Handshaking',\n",
       " '55--Sports_Coach_Trainer',\n",
       " '35--Basketball',\n",
       " '38--Tennis',\n",
       " '24--Soldier_Firing',\n",
       " '53--Raid',\n",
       " '49--Greeting',\n",
       " '32--Worker_Laborer',\n",
       " '4--Dancing',\n",
       " '31--Waiter_Waitress',\n",
       " '47--Matador_Bullfighter',\n",
       " '19--Couple',\n",
       " '28--Sports_Fan',\n",
       " '61--Street_Battle',\n",
       " '40--Gymnastics',\n",
       " '2--Demonstration',\n",
       " '42--Car_Racing',\n",
       " '58--Hockey',\n",
       " '14--Traffic',\n",
       " '26--Soldier_Drilling',\n",
       " '12--Group',\n",
       " '37--Soccer',\n",
       " '50--Celebration_Or_Party',\n",
       " '43--Row_Boat',\n",
       " '22--Picnic',\n",
       " '11--Meeting',\n",
       " '59--people--driving--car',\n",
       " '51--Dresses',\n",
       " '45--Balloonist',\n",
       " '10--People_Marching',\n",
       " '25--Soldier_Patrol',\n",
       " '13--Interview',\n",
       " '41--Swimming',\n",
       " '5--Car_Accident',\n",
       " '17--Ceremony',\n",
       " '9--Press_Conference',\n",
       " '44--Aerobics',\n",
       " '21--Festival',\n",
       " '23--Shoppers',\n",
       " '0--Parade',\n",
       " '33--Running',\n",
       " '57--Angler',\n",
       " '6--Funeral',\n",
       " '30--Surgeons',\n",
       " '46--Jockey',\n",
       " '3--Riot',\n",
       " '29--Students_Schoolkids',\n",
       " '8--Election_Campain',\n",
       " '15--Stock_Market',\n",
       " '34--Baseball',\n",
       " '20--Family_Group',\n",
       " '18--Concerts',\n",
       " '7--Cheering',\n",
       " '39--Ice_Skating',\n",
       " '56--Voter',\n",
       " '54--Rescue',\n",
       " '36--Football',\n",
       " '48--Parachutist_Paratrooper',\n",
       " '16--Award_Ceremony',\n",
       " '52--Photographers']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(preds.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds['16--Award_Ceremony'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16_Award_Ceremony_Awards_Ceremony_16_226',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_305',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_589',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_392',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_56',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_750',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_73',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_512',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_116',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_447',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_569',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_752',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_84',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_231',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_361',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_467',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_474',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_546',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_495',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_195',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_85',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_309',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_346',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_134',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_143',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_124',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_64',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_59',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_311',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_317',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_490',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_637',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_270',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_566',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_141',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_524',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_338',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_422',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_591',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_135',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_482',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_94',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_239',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_25',\n",
       " '16_Award_Ceremony_Awards_Ceremony_16_4']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(preds['16--Award_Ceremony'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.02000000e+02,  9.40000000e+01,  3.30000000e+01,\n",
       "         4.40000000e+01,  9.98788900e-01],\n",
       "       [ 4.40000000e+02,  1.22000000e+02,  3.30000000e+01,\n",
       "         4.30000000e+01,  9.97949060e-01],\n",
       "       [ 8.43000000e+02,  1.33000000e+02,  3.80000000e+01,\n",
       "         4.70000000e+01,  9.97211640e-01],\n",
       "       [ 6.50000000e+02,  1.37000000e+02,  3.80000000e+01,\n",
       "         4.70000000e+01,  9.96059950e-01],\n",
       "       [ 5.63000000e+02,  1.03000000e+02,  4.00000000e+01,\n",
       "         5.40000000e+01,  9.95707300e-01],\n",
       "       [ 2.25000000e+02,  1.18000000e+02,  3.90000000e+01,\n",
       "         4.90000000e+01,  9.92876200e-01],\n",
       "       [ 7.40000000e+02,  1.46000000e+02,  4.20000000e+01,\n",
       "         5.50000000e+01,  9.90303930e-01],\n",
       "       [ 9.29000000e+02,  1.53000000e+02,  4.20000000e+01,\n",
       "         5.40000000e+01,  9.86212000e-01],\n",
       "       [ 1.49000000e+02,  9.60000000e+01,  3.90000000e+01,\n",
       "         5.40000000e+01,  9.85900000e-01],\n",
       "       [ 3.32000000e+02,  1.48000000e+02,  4.30000000e+01,\n",
       "         5.20000000e+01,  9.83178730e-01],\n",
       "       [ 6.00000000e+01,  1.02000000e+02,  4.40000000e+01,\n",
       "         5.20000000e+01,  9.65731440e-01],\n",
       "       [ 6.60000000e+02,  3.13000000e+02,  1.80000000e+01,\n",
       "         2.30000000e+01,  5.20748850e-01],\n",
       "       [ 4.29000000e+02,  4.29000000e+02,  1.00000000e+01,\n",
       "         1.30000000e+01,  1.27731220e-01],\n",
       "       [ 6.81000000e+02,  3.03000000e+02,  1.90000000e+01,\n",
       "         2.40000000e+01,  1.23169790e-01],\n",
       "       [ 9.29000000e+02,  3.56000000e+02,  2.70000000e+01,\n",
       "         3.00000000e+01,  1.22469015e-01],\n",
       "       [ 2.54000000e+02,  1.22000000e+02,  2.90000000e+01,\n",
       "         3.90000000e+01,  6.48160500e-02],\n",
       "       [ 4.30000000e+02,  4.25000000e+02,  8.00000000e+00,\n",
       "         1.10000000e+01,  6.40430150e-02],\n",
       "       [ 8.61000000e+02,  3.53000000e+02,  1.80000000e+01,\n",
       "         2.30000000e+01,  5.06184700e-02],\n",
       "       [ 7.33000000e+02,  3.86000000e+02,  1.40000000e+01,\n",
       "         1.80000000e+01,  4.59200030e-02],\n",
       "       [ 4.57000000e+02,  4.15000000e+02,  7.00000000e+00,\n",
       "         1.00000000e+01,  4.29894780e-02],\n",
       "       [ 6.70000000e+02,  3.06000000e+02,  2.40000000e+01,\n",
       "         2.80000000e+01,  4.07238640e-02],\n",
       "       [ 1.94000000e+02, -2.00000000e+00,  1.70000000e+01,\n",
       "         1.90000000e+01,  3.06761260e-02],\n",
       "       [ 8.06000000e+02,  3.80000000e+02,  1.40000000e+01,\n",
       "         1.70000000e+01,  3.03399840e-02],\n",
       "       [ 4.26000000e+02,  4.25000000e+02,  9.00000000e+00,\n",
       "         1.10000000e+01,  3.03372300e-02],\n",
       "       [ 7.49000000e+02,  3.71000000e+02,  1.40000000e+01,\n",
       "         1.80000000e+01,  3.00300590e-02],\n",
       "       [ 4.66000000e+02,  4.32000000e+02,  7.00000000e+00,\n",
       "         9.00000000e+00,  2.91325410e-02],\n",
       "       [ 7.92000000e+02,  4.22000000e+02,  9.00000000e+00,\n",
       "         1.20000000e+01,  2.81868740e-02],\n",
       "       [ 4.88000000e+02,  3.81000000e+02,  7.00000000e+00,\n",
       "         1.00000000e+01,  2.81583930e-02],\n",
       "       [ 4.39000000e+02,  3.50000000e+02,  8.00000000e+00,\n",
       "         1.00000000e+01,  2.70269770e-02],\n",
       "       [ 7.59000000e+02,  3.48000000e+02,  1.10000000e+01,\n",
       "         1.30000000e+01,  2.70206820e-02],\n",
       "       [ 4.70000000e+02,  3.82000000e+02,  7.00000000e+00,\n",
       "         9.00000000e+00,  2.62754730e-02],\n",
       "       [ 4.86000000e+02,  4.00000000e+02,  7.00000000e+00,\n",
       "         1.00000000e+01,  2.61523700e-02],\n",
       "       [ 7.26000000e+02,  3.93000000e+02,  1.40000000e+01,\n",
       "         1.60000000e+01,  2.59289200e-02],\n",
       "       [ 7.92000000e+02,  4.67000000e+02,  1.60000000e+01,\n",
       "         1.80000000e+01,  2.56900700e-02],\n",
       "       [ 4.70000000e+02,  3.91000000e+02,  7.00000000e+00,\n",
       "         9.00000000e+00,  2.54084020e-02],\n",
       "       [ 8.14000000e+02,  4.04000000e+02,  1.00000000e+01,\n",
       "         1.30000000e+01,  2.52930000e-02],\n",
       "       [ 4.56000000e+02,  3.83000000e+02,  6.00000000e+00,\n",
       "         8.00000000e+00,  2.50633580e-02],\n",
       "       [ 1.68000000e+02,  5.00000000e+01,  3.70000000e+01,\n",
       "         4.80000000e+01,  2.49868400e-02],\n",
       "       [ 4.81000000e+02,  4.08000000e+02,  7.00000000e+00,\n",
       "         9.00000000e+00,  2.47679300e-02],\n",
       "       [ 4.70000000e+02,  3.75000000e+02,  8.00000000e+00,\n",
       "         1.00000000e+01,  2.41722220e-02],\n",
       "       [ 4.89000000e+02,  3.76000000e+02,  6.00000000e+00,\n",
       "         8.00000000e+00,  2.38421410e-02],\n",
       "       [ 5.13000000e+02,  3.76000000e+02,  8.00000000e+00,\n",
       "         1.00000000e+01,  2.34231050e-02],\n",
       "       [ 4.66000000e+02,  3.83000000e+02,  8.00000000e+00,\n",
       "         9.00000000e+00,  2.33671800e-02],\n",
       "       [ 2.14000000e+02,  8.10000000e+01,  2.20000000e+01,\n",
       "         2.90000000e+01,  2.31270030e-02],\n",
       "       [ 7.58000000e+02,  4.07000000e+02,  1.30000000e+01,\n",
       "         1.50000000e+01,  2.25128830e-02],\n",
       "       [ 6.51000000e+02,  2.81000000e+02,  4.30000000e+01,\n",
       "         5.30000000e+01,  2.24516520e-02],\n",
       "       [ 4.73000000e+02,  4.08000000e+02,  7.00000000e+00,\n",
       "         1.00000000e+01,  2.24316920e-02],\n",
       "       [ 5.35000000e+02,  1.36000000e+02,  2.40000000e+01,\n",
       "         3.00000000e+01,  2.20017140e-02],\n",
       "       [ 4.71000000e+02,  4.38000000e+02,  7.00000000e+00,\n",
       "         1.00000000e+01,  2.18082930e-02],\n",
       "       [ 1.84000000e+02,  2.49000000e+02,  2.90000000e+01,\n",
       "         4.20000000e+01,  2.17273590e-02],\n",
       "       [ 4.71000000e+02,  4.14000000e+02,  8.00000000e+00,\n",
       "         1.00000000e+01,  2.05764040e-02],\n",
       "       [ 4.71000000e+02,  4.24000000e+02,  7.00000000e+00,\n",
       "         1.00000000e+01,  2.03217770e-02]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds['16--Award_Ceremony']['16_Award_Ceremony_Awards_Ceremony_16_25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds['16--Award_Ceremony']['16_Award_Ceremony_Awards_Ceremony_16_25'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "from data import cfg_mnet, cfg_re50\n",
    "from layers.functions.prior_box import PriorBox\n",
    "from utils.nms.py_cpu_nms import py_cpu_nms\n",
    "import cv2\n",
    "from models.retinaface import RetinaFace\n",
    "from utils.box_utils import decode, decode_landm\n",
    "from utils.timer import Timer\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Retinaface')\n",
    "parser.add_argument('-m', '--trained_model', default='./weights/Resnet50_Final.pth',\n",
    "                    type=str, help='Trained state_dict file path to open')\n",
    "parser.add_argument('--network', default='resnet50', help='Backbone network mobile0.25 or resnet50')\n",
    "parser.add_argument('--origin_size', default=True, type=str, help='Whether use origin image size to evaluate')\n",
    "parser.add_argument('--save_folder', default='./widerface_evaluate/widerface_txt/', type=str, help='Dir to save txt results')\n",
    "parser.add_argument('--cpu', action=\"store_true\", default=False, help='Use cpu inference')\n",
    "parser.add_argument('--dataset_folder', default='./data/widerface/val/images/', type=str, help='dataset path')\n",
    "parser.add_argument('--confidence_threshold', default=0.02, type=float, help='confidence_threshold')\n",
    "parser.add_argument('--top_k', default=5000, type=int, help='top_k')\n",
    "parser.add_argument('--nms_threshold', default=0.4, type=float, help='nms_threshold')\n",
    "parser.add_argument('--keep_top_k', default=750, type=int, help='keep_top_k')\n",
    "parser.add_argument('-s', '--save_image', action=\"store_true\", default=False, help='show detection results')\n",
    "parser.add_argument('--vis_thres', default=0.5, type=float, help='visualization_threshold')\n",
    "#args = parser.parse_args()\n",
    "\n",
    "args = argparse.Namespace()\n",
    "args.trained_model = './weights/pretrain/mobilenet0.25_Final.pth'\n",
    "args.network = 'mobile0.25'\n",
    "args.origin_size = True\n",
    "args.save_folder = './widerface_evaluate/widerface_txt/'\n",
    "args.cpu = False\n",
    "args.dataset_folder = './data/widerface/val/images/'\n",
    "args.confidence_threshold = 0.02\n",
    "args.top_k = 5000\n",
    "args.nms_threshold = 0.4\n",
    "args.keep_top_k = 750\n",
    "args.save_image = False\n",
    "args.vis_thres = 0.5\n",
    "\n",
    "\n",
    "def check_keys(model, pretrained_state_dict):\n",
    "    ckpt_keys = set(pretrained_state_dict.keys())\n",
    "    model_keys = set(model.state_dict().keys())\n",
    "    used_pretrained_keys = model_keys & ckpt_keys\n",
    "    unused_pretrained_keys = ckpt_keys - model_keys\n",
    "    missing_keys = model_keys - ckpt_keys\n",
    "    print('Missing keys:{}'.format(len(missing_keys)))\n",
    "    print('Unused checkpoint keys:{}'.format(len(unused_pretrained_keys)))\n",
    "    print('Used keys:{}'.format(len(used_pretrained_keys)))\n",
    "    assert len(used_pretrained_keys) > 0, 'load NONE from pretrained checkpoint'\n",
    "    return True\n",
    "\n",
    "\n",
    "def remove_prefix(state_dict, prefix):\n",
    "    ''' Old style model is stored with all names of parameters sharing common prefix 'module.' '''\n",
    "    print('remove prefix \\'{}\\''.format(prefix))\n",
    "    f = lambda x: x.split(prefix, 1)[-1] if x.startswith(prefix) else x\n",
    "    return {f(key): value for key, value in state_dict.items()}\n",
    "\n",
    "\n",
    "def load_model(model, pretrained_path, load_to_cpu):\n",
    "    print('Loading pretrained model from {}'.format(pretrained_path))\n",
    "    if load_to_cpu:\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage)\n",
    "    else:\n",
    "        device = torch.cuda.current_device()\n",
    "        pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))\n",
    "    if \"state_dict\" in pretrained_dict.keys():\n",
    "        pretrained_dict = remove_prefix(pretrained_dict['state_dict'], 'module.')\n",
    "    else:\n",
    "        pretrained_dict = remove_prefix(pretrained_dict, 'module.')\n",
    "    check_keys(model, pretrained_dict)\n",
    "    model.load_state_dict(pretrained_dict, strict=False)\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def predict():\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    cfg = None\n",
    "    if args.network == \"mobile0.25\":\n",
    "        cfg = cfg_mnet\n",
    "    elif args.network == \"resnet50\":\n",
    "        cfg = cfg_re50\n",
    "    # net and model\n",
    "    net = RetinaFace(cfg=cfg, phase = 'test')\n",
    "    net = load_model(net, args.trained_model, args.cpu)\n",
    "    net.eval()\n",
    "    print('Finished loading model!')\n",
    "    #print(net)\n",
    "    cudnn.benchmark = True\n",
    "    device = torch.device(\"cpu\" if args.cpu else \"cuda\")\n",
    "    net = net.to(device)\n",
    "\n",
    "    # testing dataset\n",
    "    testset_folder = args.dataset_folder\n",
    "    testset_list = args.dataset_folder[:-7] + \"wider_val.txt\"\n",
    "\n",
    "    with open(testset_list, 'r') as fr:\n",
    "        test_dataset = fr.read().split()\n",
    "    num_images = len(test_dataset)\n",
    "\n",
    "    _t = {'forward_pass': Timer(), 'misc': Timer()}\n",
    "\n",
    "    # testing begin\n",
    "    results = defaultdict(dict)\n",
    "    for i, img_name in enumerate(test_dataset):\n",
    "        image_path = testset_folder + img_name\n",
    "        img_raw = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        img = np.float32(img_raw)\n",
    "\n",
    "        # testing scale\n",
    "        target_size = 1600\n",
    "        max_size = 2150\n",
    "        im_shape = img.shape\n",
    "        im_size_min = np.min(im_shape[0:2])\n",
    "        im_size_max = np.max(im_shape[0:2])\n",
    "        resize = float(target_size) / float(im_size_min)\n",
    "        # prevent bigger axis from being more than max_size:\n",
    "        if np.round(resize * im_size_max) > max_size:\n",
    "            resize = float(max_size) / float(im_size_max)\n",
    "        if args.origin_size:\n",
    "            resize = 1\n",
    "\n",
    "        if resize != 1:\n",
    "            img = cv2.resize(img, None, None, fx=resize, fy=resize, interpolation=cv2.INTER_LINEAR)\n",
    "        im_height, im_width, _ = img.shape\n",
    "        scale = torch.Tensor([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "        img -= (104, 117, 123)\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        img = torch.from_numpy(img).unsqueeze(0)\n",
    "        img = img.to(device)\n",
    "        scale = scale.to(device)\n",
    "\n",
    "        _t['forward_pass'].tic()\n",
    "        loc, conf, landms = net(img)  # forward pass\n",
    "        _t['forward_pass'].toc()\n",
    "        _t['misc'].tic()\n",
    "        priorbox = PriorBox(cfg, image_size=(im_height, im_width))\n",
    "        priors = priorbox.forward()\n",
    "        priors = priors.to(device)\n",
    "        prior_data = priors.data\n",
    "        boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
    "        boxes = boxes * scale / resize\n",
    "        boxes = boxes.cpu().numpy()\n",
    "        scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
    "        landms = decode_landm(landms.data.squeeze(0), prior_data, cfg['variance'])\n",
    "        scale1 = torch.Tensor([img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                               img.shape[3], img.shape[2], img.shape[3], img.shape[2],\n",
    "                               img.shape[3], img.shape[2]])\n",
    "        scale1 = scale1.to(device)\n",
    "        landms = landms * scale1 / resize\n",
    "        landms = landms.cpu().numpy()\n",
    "\n",
    "        # ignore low scores\n",
    "        inds = np.where(scores > args.confidence_threshold)[0]\n",
    "        boxes = boxes[inds]\n",
    "        landms = landms[inds]\n",
    "        scores = scores[inds]\n",
    "\n",
    "        # keep top-K before NMS\n",
    "        order = scores.argsort()[::-1]\n",
    "        # order = scores.argsort()[::-1][:args.top_k]\n",
    "        boxes = boxes[order]\n",
    "        landms = landms[order]\n",
    "        scores = scores[order]\n",
    "\n",
    "        # do NMS\n",
    "        dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "        keep = py_cpu_nms(dets, args.nms_threshold)\n",
    "        # keep = nms(dets, args.nms_threshold,force_cpu=args.cpu)\n",
    "        dets = dets[keep, :]\n",
    "        landms = landms[keep]\n",
    "\n",
    "        # keep top-K faster NMS\n",
    "        # dets = dets[:args.keep_top_k, :]\n",
    "        # landms = landms[:args.keep_top_k, :]\n",
    "\n",
    "        dets = np.concatenate((dets, landms), axis=1)\n",
    "        _t['misc'].toc()\n",
    "        \n",
    "        event = img_name.split('/')[1]\n",
    "        event_img = img_name.split('/')[2][:-4]\n",
    "\n",
    "        if event_img not in results[event]:\n",
    "            results[event][event_img] = []\n",
    "            \n",
    "        # --------------------------------------------------------------------\n",
    "        save_name = args.save_folder + img_name[:-4] + \".txt\"\n",
    "        dirname = os.path.dirname(save_name)\n",
    "        if not os.path.isdir(dirname):\n",
    "            os.makedirs(dirname)\n",
    "        with open(save_name, \"w\") as fd:\n",
    "            bboxs = dets\n",
    "            file_name = os.path.basename(save_name)[:-4] + \"\\n\"\n",
    "            bboxs_num = str(len(bboxs)) + \"\\n\"\n",
    "            fd.write(file_name)\n",
    "            fd.write(bboxs_num)\n",
    "            print('dir:', dirname)\n",
    "            print('img_name:', img_name)\n",
    "            print('file:', file_name)\n",
    "            print(bboxs_num)\n",
    "            for box in bboxs:\n",
    "                x = int(box[0])\n",
    "                y = int(box[1])\n",
    "                w = int(box[2]) - int(box[0])\n",
    "                h = int(box[3]) - int(box[1])\n",
    "                confidence = str(box[4])\n",
    "                line = str(x) + \" \" + str(y) + \" \" + str(w) + \" \" + str(h) + \" \" + confidence + \" \\n\"\n",
    "                #fd.write(line)\n",
    "                print(line)\n",
    "\n",
    "        #print('im_detect: {:d}/{:d} forward_pass_time: {:.4f}s misc: {:.4f}s'.format(i + 1, num_images, _t['forward_pass'].average_time, _t['misc'].average_time))\n",
    "        #print('line:', line)\n",
    "        print('dets:', dets)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from ./weights/pretrain/mobilenet0.25_Final.pth\n",
      "remove prefix 'module.'\n",
      "Missing keys:0\n",
      "Unused checkpoint keys:0\n",
      "Used keys:300\n",
      "Finished loading model!\n",
      "dir: ./widerface_evaluate/widerface_txt//24--Soldier_Firing\n",
      "img_name: /24--Soldier_Firing/24_Soldier_Firing_Soldier_Firing_24_329.jpg\n",
      "file: 24_Soldier_Firing_Soldier_Firing_24_329\n",
      "\n",
      "6\n",
      "\n",
      "884 194 123 142 0.81570655 \n",
      "\n",
      "882 346 105 114 0.090121895 \n",
      "\n",
      "594 293 176 245 0.06757448 \n",
      "\n",
      "344 179 328 473 0.025667015 \n",
      "\n",
      "668 396 29 33 0.025203438 \n",
      "\n",
      "845 186 179 259 0.021932088 \n",
      "\n",
      "dets: [[8.8433685e+02 1.9427991e+02 1.0076625e+03 3.3636084e+02 8.1570655e-01\n",
      "  9.0050262e+02 2.4671545e+02 9.4849384e+02 2.4304390e+02 9.1522015e+02\n",
      "  2.8052585e+02 9.2020209e+02 3.0874371e+02 9.5279761e+02 3.0545010e+02]\n",
      " [8.8296826e+02 3.4696515e+02 9.8761560e+02 4.6025662e+02 9.0121895e-02\n",
      "  9.1701556e+02 3.8799265e+02 9.5402771e+02 3.8312177e+02 9.4254816e+02\n",
      "  4.0152563e+02 9.2681958e+02 4.2465784e+02 9.5531165e+02 4.2107053e+02]\n",
      " [5.9468719e+02 2.9342944e+02 7.7040100e+02 5.3826917e+02 6.7574479e-02\n",
      "  6.5606573e+02 3.8732471e+02 7.0476935e+02 3.8549246e+02 6.8127869e+02\n",
      "  4.2008630e+02 6.6327625e+02 4.6253076e+02 6.9760175e+02 4.6224451e+02]\n",
      " [3.4416071e+02 1.7948856e+02 6.7227637e+02 6.5282324e+02 2.5667015e-02\n",
      "  4.4985513e+02 3.8795193e+02 5.5745380e+02 3.8861328e+02 5.0249524e+02\n",
      "  4.9263693e+02 4.6155887e+02 5.5322980e+02 5.4206787e+02 5.5444171e+02]\n",
      " [6.6840430e+02 3.9605490e+02 6.9701721e+02 4.2910001e+02 2.5203438e-02\n",
      "  6.7682794e+02 4.0994464e+02 6.8774194e+02 4.1088181e+02 6.8175342e+02\n",
      "  4.1742862e+02 6.7773651e+02 4.2202698e+02 6.8538489e+02 4.2266312e+02]\n",
      " [8.4592126e+02 1.8663336e+02 1.0240765e+03 4.4519965e+02 2.1932088e-02\n",
      "  8.9251178e+02 2.7692496e+02 9.5418262e+02 2.6870090e+02 9.2068243e+02\n",
      "  3.2092105e+02 9.1030865e+02 3.7693478e+02 9.4975000e+02 3.7048804e+02]]\n"
     ]
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./widerface_evaluate/widerface_txt//24--Soldier_Firing/24_Soldier_Firing_Soldier_Firing_24_329.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./widerface_evaluate/widerface_txt//24--Soldier_Firing/24_Soldier_Firing_Soldier_Firing_24_329.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '24--Soldier_Firing', '24_Soldier_Firing_Soldier_Firing_24_329.jpg']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/24--Soldier_Firing/24_Soldier_Firing_Soldier_Firing_24_329.jpg'.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'24_Soldier_Firing_Soldier_Firing_24_329'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/24--Soldier_Firing/24_Soldier_Firing_Soldier_Firing_24_329.jpg'.split('/')[2][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = defaultdict(dict)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "first argument must be callable or None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-9bf571322d3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: first argument must be callable or None"
     ]
    }
   ],
   "source": [
    "tmp = defaultdict(list)\n",
    "results = defaultdict(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
